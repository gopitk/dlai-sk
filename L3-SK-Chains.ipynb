{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Chains in SK\n",
    "\n",
    "## Outline\n",
    "\n",
    "* Sequential Chains with kernel.run_async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541eb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84e441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a09c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n   I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78f8b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Review[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e92dff22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<semantic_kernel.kernel.Kernel at 0x7fa38641e460>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "import os\n",
    "import logging\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "# Demonstrate some basic logging to debug the chain\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger('__name__')\n",
    "kernel=sk.Kernel(log=logger)\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "kernel.add_chat_service(\n",
    "        \"chat-gpt\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdcdb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the best name to describe \\\n",
    "    a company that makes {{ $input }} ?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f1299f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: What is the best name to describe     a company that makes {{ $input }} ?\n"
     ]
    }
   ],
   "source": [
    "# Create a semantic function based on prompt to name a company based on product it makes. \n",
    "# Make it creative by setting a high temperature for the LLM\n",
    "productnamer = kernel.create_semantic_function(prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad44d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Rendering string template: What is the best name to describe     a company that makes {{ $input }} ?\n",
      "DEBUG:__name__:Extracting blocks from template: What is the best name to describe     a company that makes {{ $input }} ?\n",
      "DEBUG:__name__:Rendering list of 3 blocks\n",
      "DEBUG:__name__:Rendered prompt: What is the best name to describe     a company that makes Queen Size Sheet Set ?\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"What is the best name to describe     a company that makes Queen Size Sheet Set ?\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"n\": 1, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=382 request_id=53d13fc905105cee2d627d75b181a679 response_code=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Royal Comfort Beddings\n"
     ]
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "answer = await kernel.run_async(productnamer, input_str=product)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f31aa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: What is the best name to describe     a company that makes {{ $input }}?\n"
     ]
    }
   ],
   "source": [
    "# Now lets chain two skills together sequerntially with output of first passed as input to second prompt\n",
    "# prompt template 1\n",
    "first_prompt = \"What is the best name to describe \\\n",
    "    a company that makes {{ $input }}?\"\n",
    "\n",
    "# Semantic Function 1\n",
    "func_one = kernel.create_semantic_function(first_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f5d5b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: Write a 20 words description for the following     company:{{ $input }}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prompt template 2\n",
    "second_prompt = \"Write a 20 words description for the following \\\n",
    "    company:{{ $input }}\"\n",
    "\n",
    "# chain 2\n",
    "func_two = kernel.create_semantic_function(second_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c1eb2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Rendering string template: What is the best name to describe     a company that makes {{ $input }}?\n",
      "DEBUG:__name__:Extracting blocks from template: What is the best name to describe     a company that makes {{ $input }}?\n",
      "DEBUG:__name__:Rendering list of 3 blocks\n",
      "DEBUG:__name__:Rendered prompt: What is the best name to describe     a company that makes Queen Size Sheet Set?\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"What is the best name to describe     a company that makes Queen Size Sheet Set?\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"n\": 1, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=576 request_id=d463fa4449e8338ab4f6e3b9b1999210 response_code=200\n",
      "DEBUG:__name__:Rendering string template: Write a 20 words description for the following     company:{{ $input }}\n",
      "DEBUG:__name__:Extracting blocks from template: Write a 20 words description for the following     company:{{ $input }}\n",
      "DEBUG:__name__:Rendering list of 2 blocks\n",
      "DEBUG:__name__:Rendered prompt: Write a 20 words description for the following     company:\"Royal Comfort Beddings\"\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Write a 20 words description for the following     company:\\\\\"Royal Comfort Beddings\\\\\"\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"n\": 1, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=864 request_id=d2f47f8ce72edfab7b596f4f3a219416 response_code=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Royal Comfort Beddings is a luxury bedding company providing exquisite and comfortable bedding sets for a perfect night's sleep.\n"
     ]
    }
   ],
   "source": [
    "answer = await kernel.run_async(func_one, func_two, input_str=\"Queen Size Sheet Set\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## Sequential Chain\n",
    "\n",
    "Next we will look at more flexible ways to chain together semantic functions beyond a sequential pipeline. Here you need to save output of a step into context variables using Semantic Kernel's **Native Functions** which are registered as semantic functions. Currently you need to call these native semantic functions after an LLM function to store output to a specific context variable so it can be used in latter LLM functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51b04f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.skill_definition import sk_function\n",
    "from semantic_kernel.skill_definition import sk_function, sk_function_context_parameter\n",
    "from semantic_kernel import SKContext\n",
    "\n",
    "class CopyContext:\n",
    "    \"\"\"\n",
    "    Description: Copies context to do chaining\n",
    "    \"\"\"\n",
    "\n",
    "    @sk_function(\n",
    "        description=\"Copies input to another context variable\"\n",
    "    )\n",
    "    @sk_function_context_parameter(name=\"English_Review\", description=\"Review in English.\")\n",
    "    def EnglishReview(self, context: SKContext) -> str:\n",
    "        context[\"English_Review\"] = context[\"input\"]\n",
    "        return context[\"input\"]\n",
    "\n",
    "\n",
    "    @sk_function(\n",
    "        description=\"Copies input to another context variable\"\n",
    "    )\n",
    "    @sk_function_context_parameter(name=\"summary\", description=\"Review in English.\")\n",
    "    def Summary(self, context: SKContext) -> str:\n",
    "        context[\"summary\"] = context[\"input\"]\n",
    "        return context[\"input\"]\n",
    "    \n",
    "    @sk_function(\n",
    "        description=\"Copies input to another context variable\"\n",
    "    )\n",
    "    @sk_function_context_parameter(name=\"language\", description=\"Review in English.\")\n",
    "    def Language(self, context: SKContext) -> str:\n",
    "        context[\"language\"] = context[\"input\"]\n",
    "        return context[\"input\"]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8eaa9368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Importing skill _GLOBAL_FUNCTIONS_ into the global namespace\n",
      "DEBUG:__name__:Methods imported: 3\n"
     ]
    }
   ],
   "source": [
    "copy_context_skill = kernel.import_skill(CopyContext())\n",
    "v_englishreview = copy_context_skill[\"EnglishReview\"]\n",
    "v_language = copy_context_skill[\"Language\"]\n",
    "v_summary = copy_context_skill[\"Summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "661a0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "review=df.Review[5]\n",
    "context_variables = sk.ContextVariables()\n",
    "context_variables[\"review\"] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6770fd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: Translate the following review to english:\n",
      "    {{ $review }}\n"
     ]
    }
   ],
   "source": [
    "# prompt template 1: translate to english\n",
    "first_prompt = \"\"\"Translate the following review to english:\n",
    "    {{ $review }}\"\"\"\n",
    "\n",
    "# chain 1: input= Review and output= English_Review\n",
    "# Semantic Function 1\n",
    "func_one = kernel.create_semantic_function(first_prompt, temperature=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d85b363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: Can you summarize the following review in 1 sentence:\n",
      "    {{ $English_Review }}\n"
     ]
    }
   ],
   "source": [
    "second_prompt = \"\"\"Can you summarize the following review in 1 sentence:\n",
    "    {{ $English_Review }}\"\"\"\n",
    "\n",
    "# chain 2: input= English_Review and output= summary\n",
    "func_two = kernel.create_semantic_function(second_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad2f0570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Rendering string template: Translate the following review to english:\n",
      "    {{ $review }}\n",
      "DEBUG:__name__:Extracting blocks from template: Translate the following review to english:\n",
      "    {{ $review }}\n",
      "DEBUG:__name__:Rendering list of 2 blocks\n",
      "DEBUG:__name__:Rendered prompt: Translate the following review to english:\n",
      "    Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\n",
      "Vieux lot ou contrefaçon !?\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Translate the following review to english:\\\\n    Je trouve le go\\\\u00fbt m\\\\u00e9diocre. La mousse ne tient pas, c\\'est bizarre. J\\'ach\\\\u00e8te les m\\\\u00eames dans le commerce et le go\\\\u00fbt est bien meilleur...\\\\nVieux lot ou contrefa\\\\u00e7on !?\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"n\": 1, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1148 request_id=914288e6079bc74a4ec4105a2ae43861 response_code=200\n",
      "DEBUG:__name__:Rendering string template: Can you summarize the following review in 1 sentence:\n",
      "    {{ $English_Review }}\n",
      "DEBUG:__name__:Extracting blocks from template: Can you summarize the following review in 1 sentence:\n",
      "    {{ $English_Review }}\n",
      "DEBUG:__name__:Rendering list of 2 blocks\n",
      "DEBUG:__name__:Rendered prompt: Can you summarize the following review in 1 sentence:\n",
      "    I find the taste mediocre. The foam doesn't hold, it's strange. I buy the same ones in stores and the taste is much better... Old batch or counterfeit!?\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Can you summarize the following review in 1 sentence:\\\\n    I find the taste mediocre. The foam doesn\\'t hold, it\\'s strange. I buy the same ones in stores and the taste is much better... Old batch or counterfeit!?\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"n\": 1, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1267 request_id=5b5a0ce9bf0258583cb33ec3937ea42e response_code=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reviewer finds the taste of the product mediocre and suspects that it may be an old batch or counterfeit since the foam doesn't hold and the taste is not as good as the ones bought in stores.\n"
     ]
    }
   ],
   "source": [
    "# Lets try to first chain two functions before trying a more complex chain\n",
    "# Chain looks like this: func_one-> store output in context -> func_two\n",
    "answer = await kernel.run_async(func_one, v_englishreview,func_two, input_vars=context_variables)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64a223a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: What language is the following review:\n",
      "\n",
      "{{ $review }}\n"
     ]
    }
   ],
   "source": [
    "# Now lets chain more functions together in more flexible manner\n",
    "# prompt template 3: translate to english\n",
    "third_prompt = \"What language is the following review:\\n\\n{{ $review }}\"\n",
    "\n",
    "# chain 3: input= Review and output= language\n",
    "func_three = kernel.create_semantic_function(third_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7137b965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: Write a follow up response to the following \n",
      "    summary in the specified language:\n",
      "    Summary: {{ $summary }}\n",
      "\n",
      "Language: {{ $language }}\n"
     ]
    }
   ],
   "source": [
    "# prompt template 4: follow up message\n",
    "fourth_prompt = \"\"\"Write a follow up response to the following \n",
    "    summary in the specified language:\n",
    "    Summary: {{ $summary }}\\n\\nLanguage: {{ $language }}\"\"\"\n",
    "\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "func_four = kernel.create_semantic_function(fourth_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9031d4",
   "metadata": {},
   "source": [
    "Now call a more elaborate chain where output from a step is used as input not just in next step\n",
    "Chain looks like this:\n",
    "<pre>\n",
    "                                         +-----------------------------\n",
    "                                         |                            |\n",
    "                                         |                            V\n",
    " (Input)Review ----> func_one   --->  func_two  func_three  ----->  func_four\n",
    "          |                                        ^\n",
    "          |                                        |\n",
    "          +-----------------------------------------\n",
    "</pre>\n",
    "   \n",
    "Notice that after each function , we have to call a native function (like v_englighreview, v_summary, v_language) to store output in context so it can be referenced in a subsequent step. In kernel.run_async you can specify a list of functions (semantic or native function) to call which it does in sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d901c399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Rendering string template: Translate the following review to english:\n",
      "    {{ $review }}\n",
      "DEBUG:__name__:Extracting blocks from template: Translate the following review to english:\n",
      "    {{ $review }}\n",
      "DEBUG:__name__:Rendering list of 2 blocks\n",
      "DEBUG:__name__:Rendered prompt: Translate the following review to english:\n",
      "    Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\n",
      "Vieux lot ou contrefaçon !?\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Translate the following review to english:\\\\n    Je trouve le go\\\\u00fbt m\\\\u00e9diocre. La mousse ne tient pas, c\\'est bizarre. J\\'ach\\\\u00e8te les m\\\\u00eames dans le commerce et le go\\\\u00fbt est bien meilleur...\\\\nVieux lot ou contrefa\\\\u00e7on !?\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"n\": 1, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1151 request_id=5710c9c2776c9759925def2261425f7f response_code=200\n",
      "DEBUG:__name__:Rendering string template: Can you summarize the following review in 1 sentence:\n",
      "    {{ $English_Review }}\n",
      "DEBUG:__name__:Extracting blocks from template: Can you summarize the following review in 1 sentence:\n",
      "    {{ $English_Review }}\n",
      "DEBUG:__name__:Rendering list of 2 blocks\n",
      "DEBUG:__name__:Rendered prompt: Can you summarize the following review in 1 sentence:\n",
      "    I find the taste mediocre. The foam doesn't hold, it's weird. I buy the same ones in stores and the taste is much better...\n",
      "Old batch or counterfeit?!\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Can you summarize the following review in 1 sentence:\\\\n    I find the taste mediocre. The foam doesn\\'t hold, it\\'s weird. I buy the same ones in stores and the taste is much better...\\\\nOld batch or counterfeit?!\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"n\": 1, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1148 request_id=39017f6902b75d1468ac35fd3be4beaf response_code=200\n",
      "DEBUG:__name__:Rendering string template: What language is the following review:\n",
      "\n",
      "{{ $review }}\n",
      "DEBUG:__name__:Extracting blocks from template: What language is the following review:\n",
      "\n",
      "{{ $review }}\n",
      "DEBUG:__name__:Rendering list of 2 blocks\n",
      "DEBUG:__name__:Rendered prompt: What language is the following review:\n",
      "\n",
      "Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\n",
      "Vieux lot ou contrefaçon !?\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"What language is the following review:\\\\n\\\\nJe trouve le go\\\\u00fbt m\\\\u00e9diocre. La mousse ne tient pas, c\\'est bizarre. J\\'ach\\\\u00e8te les m\\\\u00eames dans le commerce et le go\\\\u00fbt est bien meilleur...\\\\nVieux lot ou contrefa\\\\u00e7on !?\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"n\": 1, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=421 request_id=57bd6321c7e3ef32fd043490ccda9deb response_code=200\n",
      "DEBUG:__name__:Rendering string template: Write a follow up response to the following \n",
      "    summary in the specified language:\n",
      "    Summary: {{ $summary }}\n",
      "\n",
      "Language: {{ $language }}\n",
      "DEBUG:__name__:Extracting blocks from template: Write a follow up response to the following \n",
      "    summary in the specified language:\n",
      "    Summary: {{ $summary }}\n",
      "\n",
      "Language: {{ $language }}\n",
      "DEBUG:__name__:Rendering list of 4 blocks\n",
      "DEBUG:__name__:Rendered prompt: Write a follow up response to the following \n",
      "    summary in the specified language:\n",
      "    Summary: The reviewer finds the taste of the product mediocre, with inconsistent foam and suspects the possibility of receiving an old batch or counterfeit version.\n",
      "\n",
      "Language: The language of the review is French.\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Write a follow up response to the following \\\\n    summary in the specified language:\\\\n    Summary: The reviewer finds the taste of the product mediocre, with inconsistent foam and suspects the possibility of receiving an old batch or counterfeit version.\\\\n\\\\nLanguage: The language of the review is French.\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"n\": 1, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3730 request_id=4d05303e7ecb3ba0c5fdd0176c637474 response_code=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse:\n",
      "Nous vous remercions d'avoir partagé votre avis sur notre produit. Nous sommes désolés d'apprendre que le goût ne vous a pas convaincu et que la mousse n'était pas constante. Nous tenons à vous assurer que nous prenons cela au sérieux et que nous enquêterons sur la possibilité d'un lot ancien ou d'une version contrefaite. Votre satisfaction est notre priorité et nous ferons tout notre possible pour rectifier cette situation. Si vous avez d'autres préoccupations ou des questions supplémentaires, n'hésitez pas à nous contacter. Merci encore pour votre feedback constructif.\n"
     ]
    }
   ],
   "source": [
    "answer = await kernel.run_async(func_one, v_englishreview,func_two, v_summary, func_three, v_language, func_four, input_vars=context_variables)\n",
    "\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
