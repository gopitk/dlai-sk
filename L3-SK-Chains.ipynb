{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# Chains in SK\n",
    "\n",
    "## Outline\n",
    "\n",
    "* Sequential Chains with kernel.run_async\n",
    "* Router Chain: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541eb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84e441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a09c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Product                                             Review\n",
       "0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n",
       "1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n",
       "2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n",
       "3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n",
       "4  Milk Frother Handheld\\n   I loved this product. But they only seem to l..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78f8b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Review[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b940ce7c",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e92dff22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<semantic_kernel.kernel.Kernel at 0x140ed4f7070>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "import os\n",
    "import logging\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "# Demonstrate some basic logging to debug the chain\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger('__name__')\n",
    "kernel=sk.Kernel(log=logger)\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "kernel.add_chat_service(\n",
    "        \"chat-gpt\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdcdb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the best name to describe \\\n",
    "    a company that makes {{ $input }} ?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1299f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: What is the best name to describe     a company that makes {{ $input }} ?\n"
     ]
    }
   ],
   "source": [
    "productnamer = kernel.create_semantic_function(prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad44d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Rendering string template: What is the best name to describe     a company that makes {{ $input }} ?\n",
      "DEBUG:__name__:Extracting blocks from template: What is the best name to describe     a company that makes {{ $input }} ?\n",
      "DEBUG:__name__:Rendering list of 3 blocks\n",
      "DEBUG:__name__:Rendered prompt: What is the best name to describe     a company that makes Queen Size Sheet Set ?\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"What is the best name to describe     a company that makes Queen Size Sheet Set ?\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=488 request_id=83db064944c8271e219b18dfca7a96b0 response_code=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Royal Comfort Linens.\n"
     ]
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "answer = await kernel.run_async(productnamer, input_str=product)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b03469",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f31aa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: What is the best name to describe     a company that makes {{ $input }}?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prompt template 1\n",
    "first_prompt = \"What is the best name to describe \\\n",
    "    a company that makes {{ $input }}?\"\n",
    "\n",
    "# Semantic Function 1\n",
    "func_one = kernel.create_semantic_function(first_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f5d5b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: Write a 20 words description for the following     company:{{ $input }}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prompt template 2\n",
    "second_prompt = \"Write a 20 words description for the following \\\n",
    "    company:{{ $input }}\"\n",
    "\n",
    "# chain 2\n",
    "func_two = kernel.create_semantic_function(second_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "780f747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_variables = sk.ContextVariables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c1eb2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Rendering string template: What is the best name to describe     a company that makes {{ $input }}?\n",
      "DEBUG:__name__:Extracting blocks from template: What is the best name to describe     a company that makes {{ $input }}?\n",
      "DEBUG:__name__:Rendering list of 3 blocks\n",
      "DEBUG:__name__:Rendered prompt: What is the best name to describe     a company that makes Queen Size Sheet Set?\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"What is the best name to describe     a company that makes Queen Size Sheet Set?\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=511 request_id=e92c5d2f1fbab776e7161776e796093e response_code=200\n",
      "DEBUG:__name__:Rendering string template: Write a 20 words description for the following     company:{{ $input }}\n",
      "DEBUG:__name__:Extracting blocks from template: Write a 20 words description for the following     company:{{ $input }}\n",
      "DEBUG:__name__:Rendering list of 2 blocks\n",
      "DEBUG:__name__:Rendered prompt: Write a 20 words description for the following     company:Royal Linens\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Write a 20 words description for the following     company:Royal Linens\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1396 request_id=d27cd078f55c705722ed4286496bd95d response_code=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Royal Linens is a luxury bedding and home textile brand that offers premium quality products to enhance the beauty of your home.\n"
     ]
    }
   ],
   "source": [
    "answer = await kernel.run_async(func_one, func_two, input_str=\"Queen Size Sheet Set\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ce18c",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51b04f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.skill_definition import sk_function\n",
    "from semantic_kernel.skill_definition import sk_function, sk_function_context_parameter\n",
    "from semantic_kernel import SKContext\n",
    "\n",
    "class CopyContext:\n",
    "    \"\"\"\n",
    "    Description: Copies context to do chaining\n",
    "    \"\"\"\n",
    "\n",
    "    @sk_function(\n",
    "        description=\"Copies input to another context variable\"\n",
    "    )\n",
    "    @sk_function_context_parameter(name=\"English_Review\", description=\"Review in English.\")\n",
    "    def EnglishReview(self, context: SKContext) -> str:\n",
    "        context[\"English_Review\"] = context[\"input\"]\n",
    "        return context[\"input\"]\n",
    "\n",
    "\n",
    "    @sk_function(\n",
    "        description=\"Copies input to another context variable\"\n",
    "    )\n",
    "    @sk_function_context_parameter(name=\"summary\", description=\"Review in English.\")\n",
    "    def Summary(self, context: SKContext) -> str:\n",
    "        context[\"summary\"] = context[\"input\"]\n",
    "        return context[\"input\"]\n",
    "    \n",
    "    @sk_function(\n",
    "        description=\"Copies input to another context variable\"\n",
    "    )\n",
    "    @sk_function_context_parameter(name=\"language\", description=\"Review in English.\")\n",
    "    def Language(self, context: SKContext) -> str:\n",
    "        context[\"language\"] = context[\"input\"]\n",
    "        return context[\"input\"]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8eaa9368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Importing skill _GLOBAL_FUNCTIONS_ into the global namespace\n",
      "DEBUG:__name__:Methods imported: 3\n"
     ]
    }
   ],
   "source": [
    "copy_context_skill = kernel.import_skill(CopyContext())\n",
    "v_englishreview = copy_context_skill[\"EnglishReview\"]\n",
    "v_language = copy_context_skill[\"Language\"]\n",
    "v_summary = copy_context_skill[\"Summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "661a0820",
   "metadata": {},
   "outputs": [],
   "source": [
    "review=df.Review[5]\n",
    "context_variables[\"review\"] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6770fd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: Translate the following review to english:\n",
      "    {{ $review }}\n"
     ]
    }
   ],
   "source": [
    "# prompt template 1: translate to english\n",
    "first_prompt = \"\"\"Translate the following review to english:\n",
    "    {{ $review }}\"\"\"\n",
    "\n",
    "# chain 1: input= Review and output= English_Review\n",
    "# Semantic Function 1\n",
    "func_one = kernel.create_semantic_function(first_prompt, temperature=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2d85b363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: Can you summarize the following review in 1 sentence:\n",
      "    {{ $English_Review }}\n"
     ]
    }
   ],
   "source": [
    "second_prompt = \"\"\"Can you summarize the following review in 1 sentence:\n",
    "    {{ $English_Review }}\"\"\"\n",
    "\n",
    "# chain 2: input= English_Review and output= summary\n",
    "func_two = kernel.create_semantic_function(second_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad2f0570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Rendering string template: Translate the following review to english:\n",
      "    {{ $input }}\n",
      "DEBUG:__name__:Extracting blocks from template: Translate the following review to english:\n",
      "    {{ $input }}\n",
      "DEBUG:__name__:Rendering list of 2 blocks\n",
      "DEBUG:__name__:Rendered prompt: Translate the following review to english:\n",
      "    Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\n",
      "Vieux lot ou contrefaçon !?\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Translate the following review to english:\\\\n    Je trouve le go\\\\u00fbt m\\\\u00e9diocre. La mousse ne tient pas, c\\'est bizarre. J\\'ach\\\\u00e8te les m\\\\u00eames dans le commerce et le go\\\\u00fbt est bien meilleur...\\\\nVieux lot ou contrefa\\\\u00e7on !?\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1725 request_id=26f610a3cabc5d70c500e9af8e4b14c9 response_code=200\n",
      "DEBUG:__name__:Rendering string template: Can you summarize the following review in 1 sentence:\n",
      "    {{ $English_Review }}\n",
      "DEBUG:__name__:Extracting blocks from template: Can you summarize the following review in 1 sentence:\n",
      "    {{ $English_Review }}\n",
      "DEBUG:__name__:Rendering list of 2 blocks\n",
      "DEBUG:__name__:Rendered prompt: Can you summarize the following review in 1 sentence:\n",
      "    I find the taste mediocre. The foam doesn't last, it's weird. I buy the same ones in stores and the taste is much better... Old batch or counterfeit!?\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Can you summarize the following review in 1 sentence:\\\\n    I find the taste mediocre. The foam doesn\\'t last, it\\'s weird. I buy the same ones in stores and the taste is much better... Old batch or counterfeit!?\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1153 request_id=9b7e1441024a82c10ef98c0d74ed3711 response_code=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reviewer found the taste mediocre and suspects the product they purchased online may be an old batch or counterfeit.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "64a223a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: What language is the following review:\n",
      "\n",
      "{{ $review }}\n"
     ]
    }
   ],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = \"What language is the following review:\\n\\n{{ $review }}\"\n",
    "\n",
    "# chain 3: input= Review and output= language\n",
    "func_three = kernel.create_semantic_function(third_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7137b965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Extracting blocks from template: Write a follow up response to the following \n",
      "    summary in the specified language:\n",
      "    Summary: {{ $summary }}\n",
      "\n",
      "Language: {{ $language }}\n"
     ]
    }
   ],
   "source": [
    "# prompt template 4: follow up message\n",
    "fourth_prompt = \"\"\"Write a follow up response to the following \n",
    "    summary in the specified language:\n",
    "    Summary: {{ $summary }}\\n\\nLanguage: {{ $language }}\"\"\"\n",
    "\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "func_four = kernel.create_semantic_function(fourth_prompt, temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d901c399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__name__:Rendering string template: Translate the following review to english:\n",
      "    {{ $review }}\n",
      "DEBUG:__name__:Extracting blocks from template: Translate the following review to english:\n",
      "    {{ $review }}\n",
      "DEBUG:__name__:Rendering list of 2 blocks\n",
      "DEBUG:__name__:Rendered prompt: Translate the following review to english:\n",
      "    Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\n",
      "Vieux lot ou contrefaçon !?\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Translate the following review to english:\\\\n    Je trouve le go\\\\u00fbt m\\\\u00e9diocre. La mousse ne tient pas, c\\'est bizarre. J\\'ach\\\\u00e8te les m\\\\u00eames dans le commerce et le go\\\\u00fbt est bien meilleur...\\\\nVieux lot ou contrefa\\\\u00e7on !?\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1701 request_id=36f769dab395e752def83e14bf886e38 response_code=200\n",
      "DEBUG:__name__:Rendering string template: Can you summarize the following review in 1 sentence:\n",
      "    {{ $English_Review }}\n",
      "DEBUG:__name__:Extracting blocks from template: Can you summarize the following review in 1 sentence:\n",
      "    {{ $English_Review }}\n",
      "DEBUG:__name__:Rendering list of 2 blocks\n",
      "DEBUG:__name__:Rendered prompt: Can you summarize the following review in 1 sentence:\n",
      "    I find the taste mediocre. The foam doesn't hold, it's weird. I buy the same ones in stores and the taste is much better... Is it an old batch or a fake!?\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Can you summarize the following review in 1 sentence:\\\\n    I find the taste mediocre. The foam doesn\\'t hold, it\\'s weird. I buy the same ones in stores and the taste is much better... Is it an old batch or a fake!?\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1220 request_id=11ada6bf3207e650195d76faee132324 response_code=200\n",
      "DEBUG:__name__:Rendering string template: What language is the following review:\n",
      "\n",
      "{{ $review }}\n",
      "DEBUG:__name__:Extracting blocks from template: What language is the following review:\n",
      "\n",
      "{{ $review }}\n",
      "DEBUG:__name__:Rendering list of 2 blocks\n",
      "DEBUG:__name__:Rendered prompt: What language is the following review:\n",
      "\n",
      "Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\n",
      "Vieux lot ou contrefaçon !?\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"What language is the following review:\\\\n\\\\nJe trouve le go\\\\u00fbt m\\\\u00e9diocre. La mousse ne tient pas, c\\'est bizarre. J\\'ach\\\\u00e8te les m\\\\u00eames dans le commerce et le go\\\\u00fbt est bien meilleur...\\\\nVieux lot ou contrefa\\\\u00e7on !?\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=826 request_id=b98a44d38f590a1ec45c420a85dffef0 response_code=200\n",
      "DEBUG:__name__:Rendering string template: Write a follow up response to the following \n",
      "    summary in the specified language:\n",
      "    Summary: {{ $summary }}\n",
      "\n",
      "Language: {{ $language }}\n",
      "DEBUG:__name__:Extracting blocks from template: Write a follow up response to the following \n",
      "    summary in the specified language:\n",
      "    Summary: {{ $summary }}\n",
      "\n",
      "Language: {{ $language }}\n",
      "DEBUG:__name__:Rendering list of 4 blocks\n",
      "DEBUG:__name__:Rendered prompt: Write a follow up response to the following \n",
      "    summary in the specified language:\n",
      "    Summary: The reviewer found the taste mediocre and the foam unsatisfactory, and questions whether the product is an old batch or fake.\n",
      "\n",
      "Language: The language of the following review is French.\n",
      "DEBUG:openai:message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai:api_version=None data='{\"model\": \"gpt-3.5-turbo\", \"messages\": [{\"role\": \"user\", \"content\": \"Write a follow up response to the following \\\\n    summary in the specified language:\\\\n    Summary: The reviewer found the taste mediocre and the foam unsatisfactory, and questions whether the product is an old batch or fake.\\\\n\\\\nLanguage: The language of the following review is French.\"}], \"temperature\": 0.9, \"top_p\": 1.0, \"presence_penalty\": 0.0, \"frequency_penalty\": 0.0, \"max_tokens\": 256, \"stream\": false}' message='Post details'\n",
      "INFO:openai:message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=13474 request_id=999980fed713de495d97764e5fb29798 response_code=200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse de suivi:\n",
      "\n",
      "Nous sommes désolés d'apprendre que vous n'avez pas été satisfait de notre produit. Nous vous assurons que nous ne vendons que des produits de la plus haute qualité et que chaque lot est soigneusement testé avant d'être mis sur le marché. Nous apprécions les commentaires de nos clients et nous travaillons constamment à améliorer nos produits. Si vous avez des questions ou des préoccupations supplémentaires, n'hésitez pas à nous contacter directement. Nous espérons avoir l'occasion de vous offrir une expérience de dégustation plus agréable à l'avenir.\n"
     ]
    }
   ],
   "source": [
    "answer = await kernel.run_async(func_one, v_englishreview,func_two, v_summary, func_three, v_language, func_four, input_vars=context_variables)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041ea4c",
   "metadata": {},
   "source": [
    "## Router Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c46ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
